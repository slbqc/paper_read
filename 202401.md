# example
> lable: 
> org: 
> data: 
> [paper arxiv]() [huggingface]()

> 总结: 

# 20240119
## Self-Rewarding Language Models 自我激励语言模型
> lable: LanguageModel,RL,Finetune,LLM-as-a-Judge
> org: Meta,纽约大学
> data: 20240118
> [paper arxiv](https://arxiv.org/abs/2401.10020)

>总结: 自我奖励语言模型，使用DPO微调，使用了LLM-as-a-judge提示，用于提供自己奖励

## ChatQA: Building GPT-4 Level Conversational QA Models 
> lable: IT,QA
> org: NVIDIA
> data: 20240118
> [paper arxiv](https://arxiv.org/abs/2401.10225)

> 总结: 提出两阶段指令调优方法，可以显著改善LLM的无提示QA结果，微调了QA的检索器（dense retriever）检索外部文件，降低部署成本，结果ChatQA-70B 优于GPT-4的QA结果

## DiffusionGPT: LLM-Driven Text-to-Image Generation System 
> lable: Text-to-Image,Diffusion
> org:ByteDance,中山大学 
> data: 20240118
> [paper arxiv](https://huggingface.co/papers/2401.10061) [huggingface](https://huggingface.co/papers/2401.10061)

> 总结: 使用LLM驱动文本到图像生产系统，待学习

## VMamba: Visual State Space Model
> lable: Visual, SSM
> org: 中国科学院大学,huawei,鹏程实验室
> data: 20240118
> [paper arxiv](https://arxiv.org/abs/2401.10166) [huggingface](https://huggingface.co/papers/2401.10166)

> 总结: 将SSM应用到视觉模型，可以在不牺牲全局视野的情况下实现线性复杂度




