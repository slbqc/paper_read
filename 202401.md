## 
> lable: 
> org: 
> data: 
> attention: 
> [paper arxiv]() [huggingface]()

> 总结: 


attention 1 当前不关注，2有点兴趣，但不关注 3 有点兴趣，对当前兴趣有一定启发 4 关注 5 关注且需要详细阅读
# 20240126

## Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All
> lable: Diffusion,Virtual Try-All
> org: 
> data: 20240126 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13795)

> 总结: 提出一个扩散模型架构，用于购物网站上的人和衣服的合并

## DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence
> lable: Coder-LLM,Model
> org: 幻方
> data: 20240129
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14196)

> 总结: 一个新的更好的辅助编码模型

## Rethinking Patch Dependence for Masked Autoencoders
> lable: Vision,BERT,MAE,Pre-Train
> org: 
> data: 20240126 
> attention: 3
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14391)

> 总结:  改进了vis transformer的训练方式：类似bert对数据的处理，将数据中的一部分遮蔽，然后预测遮蔽，方法原由何凯明提出。

## Deconstructing Denoising Diffusion Models for Self-Supervised Learning
> lable: Diffusion,self-supervised,何凯明
> org: Meta,纽约大学
> data: 20240126
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14404)

> 总结: 分析当前图像领域重要的去噪扩散模型，得出其中的关键结构

## Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI
> lable: Dataset,Language
> org: IBM
> data: 20240126
> attention: 2
> [paper arxiv]() [huggingface]()

> 总结: 当下LLM模型的训练数据格式多样，Unitxt是一个数据集共享平台，类似hugging，并提供了模型化的组件，用于语言数据集的流水线处理。

## WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models
> lable: Web,Agent,LMM
> org: 
> data: 
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13919)

> 总结: 一个多模态的web agent代理，可以通过与web进行端到端的交互来完成用户指令。

## FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
> lable: precision,float,LLM
> org: 微软
> data: 20240126
> attention: 4
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14112)

> 总结: GPU下的FP6精度处理库（可以正常任意FP精度），解决了不规则位宽的访存问题，可以在但GPU推理LLama-70B,为什么论文使用6bit，因为更小的精度随着上下文长度变长而下降。只是权重量化到FP6,计算的时候激活还是FP16

## Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities
> lable: Multimodal,train
> org: 香港大学,Tencent AI
> data: 20240126
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14405)

> 总结: 使用其他模态的数据来改进当前模态的模型效果

## BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models
> lable: train,Diffusion,Zero-shot,Text-to-Image
> org: Salesforce AI Research
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13974)

> 总结: 提供一个图片，然后加提示，生成图片，文中提到的关键是1小时完成微调

## pix2gestalt: Amodal Segmentation by Synthesizing Wholes
> lable: Segmentation,image,Diffusion
> org: 
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14398)

> 总结: 从图像中分割出对象，并补全被遮盖的地方，然后生成其3D模型

## Adaptive Mobile Manipulation for Articulated Objects In the Open World
> lable: robots,open world
> org: CMU
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14403)

> 总结: 控制在一个开放空间内机器人的自我移动，使用机械手操作各种东西的模型。

## Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation
> lable: NeRF,Text-to-3D
> org: 
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14257)

> 总结: 提供一个图片草图，然后加文本描述生产3D的具体模型

## CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion
> lable: Image,Multimodal,Diffuison
> org: 
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14066)

> 总结: 从图片中提取艺术风格，并应用到其他的图像上

## Genie: Achieving Human Parity in Content-Grounded Datasets Generation
> lable: Datasets Generation
> org: 
> data: 
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14367)

> 总结: 自动生成数据集

# 20240125

## Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild
> lable: 
> org: 
> data: 20240125
> attention: 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13627)

> 总结: 

## MM-LLMs: Recent Advances in MultiModal Large Language Models
> lable: LMM,overview
> org: Tencent Ai lab
> data: 20240125
> attention: 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13601)

> 总结: 多2023年多模态大模型的发展的综述

## MambaByte: Token-free Selective State Space Model
> lable: SSM,Mamba,Token-free
> org: 康奈尔大学
> data: 20240125
> attention: 2 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13660)

> 总结: 不适用token的语言模型，直接输入的是byte流，应用到Mamba架构

## MaLA-500: Massive Language Adaptation of Large Language Models
> lable: LLM,Model
> org: 慕尼黑大学，德国研究机构
> data: 20240125
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13303)

> 总结: 信的模型，解决在低资源语言上的效果

## UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion
> lable: LMM,Diffusion,Text-to-Image 
> org: 
> data: 20240125
> attention: 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13388)

> 总结: 输入一个图像，然后根据文字对图像进行合成。也可以输入多个图像，通过 文字对多个图像进行合成。

## SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection
> lable: Pre-traing,T5
> org: google
> data: 20240125
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13160)

> 总结: 引入了两个技术来减少预训练的迭代次数，减少迭代时间，corruption rates(动态损坏率)，就是T5(bert)这种encoder-decoder模型对数据的处理，遮掩破坏的数据比例，span corruption(连续对齐令牌的长度)跨度，即遮掩数据最长大小

## ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models
> lable: Eval,Multimodal
> org: 
> data: 20240125
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13311)

> 总结: 提出了一个多模态的基准测试集

# 20240124
## Lumiere: A Space-Time Diffusion Model for Video Generation
> lable: Text-to-Video,Diffusion
> org: google,以色列大学
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12945)

> 总结: 一种文本到视频的扩散模型，用于合成显示多样连贯运动的视频，引入了Space-Time U-Net architecture

## Small Language Model Meets with Reinforced Vision Vocabulary
> lable: VLMs,Vision,Vison Vocabulary
> org: 旷世科技，中国科学院大学，华中科技大学
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12503)

> 总结: VLMS,视觉语言模型，提出一个新的模型只需要1.8B的参数，可以在GTX 1080Ti上运行的世界模型，只要是对视觉词汇表进行改进

## Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment
> lable: LLM,Role-play,self-aligin,fine-tune
> org: alibaba
> data: 20240124
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12474)

> 总结: 提出一种自我对齐的方法Ditto，构造一个4000字符的角色训练集来增加模型的角色扮演能力，自我对齐（self-aligin)使用一个小的标注的数据集来微调可以显著提升模型能力。

## Large-scale Reinforcement Learning for Diffusion Models
> lable: RL,diffusion,Text-to-Image
> org: Pinterest ATG
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12244)

> 总结: 使用强扩学习在不同的奖励函数集上改建扩散模型

## Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding
> lable: promote,LLM,agnet,expert
> org: 斯坦福，OpenAI,微软
> data: 20240124
> attention: 4
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12954)

> 总结: 一种组合多个LM模型的图例技术，提出一个模型作为全面的协调者来协调不同专家组成的小组，从而提升性能。

## AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents
> lable: rebotic,vim,Embodied Foundataion Models(具身基础模型)
> org: Google Deepmind
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12963)

> 总结: 一种使用了视觉语言模型和大语言模型驱动的机器人自动操作的模型

## Orion-14B: Open-source Multilingual Large Language Models
> lable: LLM,Model
> org: 猎户星空(OrionStar)
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12246)

> 总结: 发布了一个多语种的模型

## BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models
> lable: inferenece acceleration,autoregressive
> org: 深圳天云励飞，哈尔滨工业大学
> data: 20240124
> attention: 3
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12522)

> 总结: 一处一种BiTA技术，用于加速LLM的推理过重，解决自回归模型无法并行问题，
每次预测多个，下次将其作为输入，比较两次输入，选择相同部分。

## GALA: Generating Animatable Layered Assets from a Single Scan
> lable: 3D,SDS,Virtual Try-All
> org: 韩国首尔大学
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12979)

> 总结: 将数据扫描生产的3D模型，进行分解，可以将让衣服和人进行分离，并将衣服和其他人组合到一起

## Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study
> lable: LLM,autogressive,non-autogressive,ASR
> org: Google Reserach
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12789)

> 总结: ASR(自动语言识别),提出一种非自回归的ASR系统设计，加速语音识别速度

# 20240123



# 20240119
## Self-Rewarding Language Models 自我激励语言模型
> lable: LLM,RL,Finetune,LLM-as-a-Judge
> org: Meta,纽约大学
> data: 20240118
> attention: 2
> [paper arxiv](https://arxiv.org/abs/2401.10020)

>总结: 自我奖励语言模型，使用DPO微调，使用了LLM-as-a-judge提示，用于提供自己奖励

## ChatQA: Building GPT-4 Level Conversational QA Models 
> lable: IT,QA
> org: NVIDIA
> data: 20240118
> attention: 2
> [paper arxiv](https://arxiv.org/abs/2401.10225)

> 总结: 提出两阶段指令调优方法，可以显著改善LLM的无提示QA结果，微调了QA的检索器（dense retriever）检索外部文件，降低部署成本，结果ChatQA-70B 优于GPT-4的QA结果

## DiffusionGPT: LLM-Driven Text-to-Image Generation System 
> lable: Text-to-Image,Diffusion
> org:ByteDance,中山大学 
> data: 20240118
> attention: 1
> [paper arxiv](https://huggingface.co/papers/2401.10061) [huggingface](https://huggingface.co/papers/2401.10061)

> 总结: 使用LLM驱动文本到图像生产系统，待学习

## VMamba: Visual State Space Model
> lable: Visual, SSM
> org: 中国科学院大学,huawei,鹏程实验室
> data: 20240118
> attention: 1
> [paper arxiv](https://arxiv.org/abs/2401.10166) [huggingface](https://huggingface.co/papers/2401.10166)

> 总结: 将SSM应用到视觉模型，可以在不牺牲全局视野的情况下实现线性复杂度


## Improving fine-grained understanding in image-text pre-training
> lable: Text-to-Image,pre-training
> org: google
> data: 20240118
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09865)

> 总结: 提升文本到图像的预训练过程中的细粒度理解。

## WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens
> lable: Text-to-Video,World_models
> org: 清华,GigaAI
> data: 20240118
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09985)

> 总结: 从大预言模型的成功中汲取灵感，将世界建模为无监督的视觉序列，然后训练模型,世界模型在理解和预测世界的动态方面起着至关重要的作用，这对视频生成至关重要。然而，现有的世界模型仅限于游戏或驾驶等特定场景，限制了它们捕捉一般世界动态环境复杂性的能力。因此，我们引入了worlddream，这是一个开创性的世界模型，旨在培养对一般世界物理和运动的全面理解，这大大增强了视频生成的能力。


## FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder
> lable: diffusion,audio
> org: 韩国科技大学
> data: 20240118
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.10032)

> 总结: 轻量级快速的频率感知的声音解码器

## Rethinking FID: Towards a Better Evaluation Metric for Image Generation
> lable: Image_Gen,Eval
> org: google,纽约大学
> data: 20231201
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09603)

> 总结: 图像生产测评

## SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild
> lable: Image-to-3D
> org: 
> data: 20240119
> attention: 1
> [paper arxiv]() [huggingface]()

> 总结: 这是一个端到端的框架，用于从不同照明、姿势和背景下捕获的物体图像中重建形状、材料和照明,从照片到3D建模

## CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects
> lable: Text-to-Video
> org: 香港中文,huawei,香港大学
> data: 20240118
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09962)

> 总结: 可以根据多个主题生成视频

