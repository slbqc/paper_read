## 
> lable: 
> org: 
> data: 
> attention: 
> 总结: 


> [paper arxiv]() [huggingface]()

attention 1 当前不关注，2有点兴趣，但不关注 3 有点兴趣，对当前兴趣有一定启发 4 关注 5 关注且需要详细阅读

# 20240126

## Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All
> lable: Diffusion,Virtual Try-All
> org: 
> data: 20240126 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13795)

> 总结: 提出一个扩散模型架构，用于购物网站上的人和衣服的合并

## DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence
> lable: Coder-LLM,Model
> org: 幻方
> data: 20240129
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14196)

> 总结: 一个新的更好的辅助编码模型

## Rethinking Patch Dependence for Masked Autoencoders
> lable: Vision,BERT,MAE,Pre-Train
> org: 
> data: 20240126 
> attention: 3
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14391)

> 总结:  改进了vis transformer的训练方式：类似bert对数据的处理，将数据中的一部分遮蔽，然后预测遮蔽，方法原由何凯明提出。

## Deconstructing Denoising Diffusion Models for Self-Supervised Learning
> lable: Diffusion,self-supervised,何凯明
> org: Meta,纽约大学
> data: 20240126
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14404)

> 总结: 分析当前图像领域重要的去噪扩散模型，得出其中的关键结构

## Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI
> lable: Dataset,Language
> org: IBM
> data: 20240126
> attention: 2
> [paper arxiv]() [huggingface]()

> 总结: 当下LLM模型的训练数据格式多样，Unitxt是一个数据集共享平台，类似hugging，并提供了模型化的组件，用于语言数据集的流水线处理。

## WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models
> lable: Web,Agent,LMM
> org: 
> data: 
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13919)

> 总结: 一个多模态的web agent代理，可以通过与web进行端到端的交互来完成用户指令。

## FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
> lable: precision,float,LLM
> org: 微软
> data: 20240126
> attention: 4
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14112)

> 总结: GPU下的FP6精度处理库（可以正常任意FP精度），解决了不规则位宽的访存问题，可以在但GPU推理LLama-70B,为什么论文使用6bit，因为更小的精度随着上下文长度变长而下降。只是权重量化到FP6,计算的时候激活还是FP16

## Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities
> lable: Multimodal,train
> org: 香港大学,Tencent AI
> data: 20240126
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14405)

> 总结: 使用其他模态的数据来改进当前模态的模型效果

## BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models
> lable: train,Diffusion,Zero-shot,Text-to-Image
> org: Salesforce AI Research
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13974)

> 总结: 提供一个图片，然后加提示，生成图片，文中提到的关键是1小时完成微调

## pix2gestalt: Amodal Segmentation by Synthesizing Wholes
> lable: Segmentation,image,Diffusion
> org: 
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14398)

> 总结: 从图像中分割出对象，并补全被遮盖的地方，然后生成其3D模型

## Adaptive Mobile Manipulation for Articulated Objects In the Open World
> lable: robots,open world
> org: CMU
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14403)

> 总结: 控制在一个开放空间内机器人的自我移动，使用机械手操作各种东西的模型。

## Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation
> lable: NeRF,Text-to-3D
> org: 
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14257)

> 总结: 提供一个图片草图，然后加文本描述生产3D的具体模型

## CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion
> lable: Image,Multimodal,Diffuison
> org: 
> data: 
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14066)

> 总结: 从图片中提取艺术风格，并应用到其他的图像上

## Genie: Achieving Human Parity in Content-Grounded Datasets Generation
> lable: Datasets Generation
> org: 
> data: 
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.14367)

> 总结: 自动生成数据集

# 20240125

## Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild
> lable: 
> org: 
> data: 20240125
> attention: 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13627)

> 总结: 

## MM-LLMs: Recent Advances in MultiModal Large Language Models
> lable: LMM,overview
> org: Tencent Ai lab
> data: 20240125
> attention: 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13601)

> 总结: 多2023年多模态大模型的发展的综述

## MambaByte: Token-free Selective State Space Model
> lable: SSM,Mamba,Token-free
> org: 康奈尔大学
> data: 20240125
> attention: 2 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13660)

> 总结: 不适用token的语言模型，直接输入的是byte流，应用到Mamba架构

## MaLA-500: Massive Language Adaptation of Large Language Models
> lable: LLM,Model
> org: 慕尼黑大学，德国研究机构
> data: 20240125
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13303)

> 总结: 信的模型，解决在低资源语言上的效果

## UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion
> lable: LMM,Diffusion,Text-to-Image 
> org: 
> data: 20240125
> attention: 
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13388)

> 总结: 输入一个图像，然后根据文字对图像进行合成。也可以输入多个图像，通过 文字对多个图像进行合成。

## SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection
> lable: Pre-traing,T5
> org: google
> data: 20240125
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13160)

> 总结: 引入了两个技术来减少预训练的迭代次数，减少迭代时间，corruption rates(动态损坏率)，就是T5(bert)这种encoder-decoder模型对数据的处理，遮掩破坏的数据比例，span corruption(连续对齐令牌的长度)跨度，即遮掩数据最长大小

## ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models
> lable: Eval,Multimodal
> org: 
> data: 20240125
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.13311)

> 总结: 提出了一个多模态的基准测试集

# 20240124
## Lumiere: A Space-Time Diffusion Model for Video Generation
> lable: Text-to-Video,Diffusion
> org: google,以色列大学
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12945)

> 总结: 一种文本到视频的扩散模型，用于合成显示多样连贯运动的视频，引入了Space-Time U-Net architecture

## Small Language Model Meets with Reinforced Vision Vocabulary
> lable: VLMs,Vision,Vison Vocabulary
> org: 旷世科技，中国科学院大学，华中科技大学
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12503)

> 总结: VLMS,视觉语言模型，提出一个新的模型只需要1.8B的参数，可以在GTX 1080Ti上运行的世界模型，只要是对视觉词汇表进行改进

## Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment
> lable: LLM,Role-play,self-aligin,fine-tune
> org: alibaba
> data: 20240124
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12474)

> 总结: 提出一种自我对齐的方法Ditto，构造一个4000字符的角色训练集来增加模型的角色扮演能力，自我对齐（self-aligin)使用一个小的标注的数据集来微调可以显著提升模型能力。

## Large-scale Reinforcement Learning for Diffusion Models
> lable: RL,diffusion,Text-to-Image
> org: Pinterest ATG
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12244)

> 总结: 使用强扩学习在不同的奖励函数集上改建扩散模型

## Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding
> lable: promote,LLM,agnet,expert
> org: 斯坦福，OpenAI,微软
> data: 20240124
> attention: 4
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12954)

> 总结: 一种组合多个LM模型的图例技术，提出一个模型作为全面的协调者来协调不同专家组成的小组，从而提升性能。

## AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents
> lable: rebotic,vim,Embodied Foundataion Models(具身基础模型)
> org: Google Deepmind
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12963)

> 总结: 一种使用了视觉语言模型和大语言模型驱动的机器人自动操作的模型

## Orion-14B: Open-source Multilingual Large Language Models
> lable: LLM,Model
> org: 猎户星空(OrionStar)
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12246)

> 总结: 发布了一个多语种的模型

## BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models
> lable: inferenece acceleration,autoregressive
> org: 深圳天云励飞，哈尔滨工业大学
> data: 20240124
> attention: 3
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12522)

> 总结: 一处一种BiTA技术，用于加速LLM的推理过重，解决自回归模型无法并行问题，
每次预测多个，下次将其作为输入，比较两次输入，选择相同部分。

## GALA: Generating Animatable Layered Assets from a Single Scan
> lable: 3D,SDS,Virtual Try-All
> org: 韩国首尔大学
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12979)

> 总结: 将数据扫描生产的3D模型，进行分解，可以将让衣服和人进行分离，并将衣服和其他人组合到一起

## Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study
> lable: LLM,autogressive,non-autogressive,ASR
> org: Google Reserach
> data: 20240124
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.12789)

> 总结: ASR(自动语言识别),提出一种非自回归的ASR系统设计，加速语音识别速度

# 20240123
## Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text
> lable: LLM,Machine-Generated
> org: Maryland,Carneigie
> data: 
> attention: 2

> 总结: 用一个模型检测文本是不是机器生成的，无需预训练即可完成

## CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark
> lable: Benchmark,Eva,Chinese
> org: 
> data: 
> attention: 1

> 总结: 一个中文的大学多个学科知识的评估数据集

## Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs
> lable: Text-toImage,Multimodal,LLM
> org: 
> data: 
> attention: 1

> 总结: 一个文生图的多模态模型

## CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation
> lable: X-Ray,Image
> org: 
> data: 
> attention: 1

> 总结: 一个用于胸部X光片的检测模型

## Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers
> lable: Diffusion,Text-to-Image
> org: Stability AI
> data: 
> attention: 1

> 总结: 一种文生图模型，可以在低像素训练，生成高像素图片

## SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities
> lable: vlm,Spatial Reasonging,VQA
> org: google
> data: 
> attention: 1

> 总结: VQA(视觉问答)理解推理图像的空间关系，VLM在VQA中不错，但是缺乏3D空间图片处理能力，开发了一个3D空间的VQA数据集，并训练了一个模型。

## DITTO: Diffusion Inference-Time T-Optimization for Music Generation
> lable: Diffusion,Music
> org: Adobo
> data: 
> attention: 1

> 总结: 使用扩散模型生成音乐（乐器，无人声）

## EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models
> lable: Diffusion,Segmentor,分割
> org: 
> data: 
> attention: 

> 总结: 图像分割技术

## WARM: On the Benefits of Weight Averaged Reward Models
> lable: fine-tune,RL,LLM,RLHF
> org: Google Deepspeed
> data: 
> attention: 2

> 总结: RL和RLHF可能因为数据集备黑客植入导致训练错误，通过使用数据训练多个模型，然后在模型之间平均权重。

## Make-A-Shape: a Ten-Million-scale 3D Shape Model
> lable: 3D,Dateset
> org: 香港中文大学
> data: 
> attention: 1

> 总结: 一个自动的3D模型生成框架，用于补充3D模型训练数据集不够的问题。

## OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics
> lable: robot
> org: 
> data: 
> attention: 1

> 总结: 提出一个Ok-Robot框架，集成多个模型来驱动机器人

## StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion
> lable: Voice conversiong,Zero-shot
> org: ASLP,ByteDance,
> data: 
> attention: 

> 总结: 用于语音转换

## UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures
> lable: 3D,Diffusion,SDS
> org: 
> data: 
> attention: 1

> 总结: 提出一个新的技术用于3D头像生成，3D头像有纹理。

## Single-View 3D Human Digitalization with Large Reconstruction Models
> lable: 3D,Human,NeRF
> org: 
> data: 
> attention: 1

> 总结: 将视频里面的人重建成3D模型

## Fast Registration of Photorealistic Avatars for VR Facial Animation
> lable: VR
> org: 斯坦福，Meta
> data: 
> attention: 1

> 总结: 用于VR场景下的脸部生成

## Scaling Face Interaction Graph Networks to Real World Scenes
> lable: Graph Network,3D
> org: Google DeepMind
> data: 
> attention: 

> 总结: 使用图网络准确模拟真实世界的物体动力学，对于机器人、工程、图形好设计应用有重大作用。

# 20240122
## Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data
> lable: Visual,Image
> org: ByteDance,香港大学,浙江大学
> data: 
> attention: 
> 总结: 估计图像中物体 的深度

## Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads
> lable: Inference,LLM
> org: 普林斯顿大学，Together AI
> data: 
> attention: 4
> 总结: LLM的自回归解码无法并行，当前推测解码来加速解码过程，但有很多挑战，提出一个独立的网络结构Medusa,可以支持在冻结的LLM(闭源提供api),或与LLM一起微调，然后加速推理。
关键是提出一个多头解码器，可以一次预测多步数据的topK,然后组合再进行预测。

## Zero Bubble Pipeline Parallelism
> lable: distributed,Pipeline,ICLR
> org: sea AI
> data: 
> attention: 5
> 总结: 提出一种新的zero bubble的pipeline方式。比1F1B提升23%。将backwar中的过程再细分为求X的梯度和求W的的梯度两部分，独立安排流水线.

## Synthesizing Moving People with 3D Control
> lable: Image-to-3D,people,diffusion
> org: UC Berkeley
> data: 
> attention: 1
> 总结: 使用扩散模型从单个照片 + 一个人物的视频，和合成照片中的人物到视频中

## Rambler: Supporting Writing With Speech via LLM-Assisted Gist Manipulation
> lable: Speech,Audio,Speech-to-text
> org: UC Berkeley,Google
> data: 
> attention: 1
> 总结: 提供一个基于LLM的语音转文本模型，支持文本摘要提取。

## ActAnywhere: Subject-Aware Video Background Generation
> lable: video,diffusion
> org: 斯坦福,Adobo
> data: 
> attention: 1
> 总结: 根据视频前景，生成背景视频

## Inflation with Diffusion: Efficient Temporal Adaptation for Text-to-Video Super-Resolution
> lable: diffusion,Text-to-video
> org: 芝加哥大学，google
> data: 
> attention: 
> 总结: 提出一个文本到视频的模型，应用了Diffuison

## Understanding Video Transformers via Universal Concept Discovery
> lable: video,transformers
> org: York,samsung,toyota
> data: 
> attention: 2
> 总结: 探索解释了via模型中各个层在视频识别中的作用，并根据发现裁剪不重要的头，可以获取4%的性能提升。




# 20240119
## Self-Rewarding Language Models 自我激励语言模型
> lable: LLM,RL,Finetune,LLM-as-a-Judge
> org: Meta,纽约大学
> data: 20240118
> attention: 2
> [paper arxiv](https://arxiv.org/abs/2401.10020)

>总结: 自我奖励语言模型，使用DPO微调，使用了LLM-as-a-judge提示，用于提供自己奖励

## ChatQA: Building GPT-4 Level Conversational QA Models 
> lable: IT,QA
> org: NVIDIA
> data: 20240118
> attention: 2
> [paper arxiv](https://arxiv.org/abs/2401.10225)

> 总结: 提出两阶段指令调优方法，可以显著改善LLM的无提示QA结果，微调了QA的检索器（dense retriever）检索外部文件，降低部署成本，结果ChatQA-70B 优于GPT-4的QA结果

## DiffusionGPT: LLM-Driven Text-to-Image Generation System 
> lable: Text-to-Image,Diffusion
> org:ByteDance,中山大学 
> data: 20240118
> attention: 1
> [paper arxiv](https://huggingface.co/papers/2401.10061) [huggingface](https://huggingface.co/papers/2401.10061)

> 总结: 使用LLM驱动文本到图像生产系统，待学习

## VMamba: Visual State Space Model
> lable: Visual, SSM
> org: 中国科学院大学,huawei,鹏程实验室
> data: 20240118
> attention: 1
> [paper arxiv](https://arxiv.org/abs/2401.10166) [huggingface](https://huggingface.co/papers/2401.10166)

> 总结: 将SSM应用到视觉模型，可以在不牺牲全局视野的情况下实现线性复杂度


## Improving fine-grained understanding in image-text pre-training
> lable: Text-to-Image,pre-training
> org: google
> data: 20240118
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09865)

> 总结: 提升文本到图像的预训练过程中的细粒度理解。

## WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens
> lable: Text-to-Video,World_models
> org: 清华,GigaAI
> data: 20240118
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09985)

> 总结: 从大预言模型的成功中汲取灵感，将世界建模为无监督的视觉序列，然后训练模型,世界模型在理解和预测世界的动态方面起着至关重要的作用，这对视频生成至关重要。然而，现有的世界模型仅限于游戏或驾驶等特定场景，限制了它们捕捉一般世界动态环境复杂性的能力。因此，我们引入了worlddream，这是一个开创性的世界模型，旨在培养对一般世界物理和运动的全面理解，这大大增强了视频生成的能力。


## FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder
> lable: diffusion,audio
> org: 韩国科技大学
> data: 20240118
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.10032)

> 总结: 轻量级快速的频率感知的声音解码器

## Rethinking FID: Towards a Better Evaluation Metric for Image Generation
> lable: Image_Gen,Eval
> org: google,纽约大学
> data: 20231201
> attention: 1
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09603)

> 总结: 图像生产测评

## SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild
> lable: Image-to-3D
> org: 
> data: 20240119
> attention: 1
> [paper arxiv]() [huggingface]()

> 总结: 这是一个端到端的框架，用于从不同照明、姿势和背景下捕获的物体图像中重建形状、材料和照明,从照片到3D建模

## CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects
> lable: Text-to-Video
> org: 香港中文,huawei,香港大学
> data: 20240118
> attention: 2
> [paper arxiv]() [huggingface](https://huggingface.co/papers/2401.09962)

> 总结: 可以根据多个主题生成视频

